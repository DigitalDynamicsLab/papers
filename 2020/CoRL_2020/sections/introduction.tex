%!TEX root = ../main.tex



\section{Introduction}

We use physics-based simulation to produce end-to-end policies for controlling AV navigation directly from raw sensory data. The AVs operate in hilly, off-road conditions with randomly placed obstacles (rocks) obstructing safe navigation. Training is based on a curriculum learning approach; the complexity of the environment is increased as the policy converges. The training is exclusively done with undeformable terrain since these simulations run faster than real time \cite{negrutGVSETS2020}. In the current implementation, deformable terrain simulation is approximately 100$ \times $ slower than the undeformable counterpart. As such, learning on deformable terrain is expensive. The control policy derived is tested on deformable soils that have different textures and soil deformation attributes. The deformable soils are of two categories: deformable but hard (silt-like), and deformable but soft (snow-like). The end-to-end approach to navigation is certainly not new, see, for instance \cite{end2endNVIDIA2016,AminiRKR19}. However, to the best of our knowledge, ($a$) this is the first example of off-road navigation (driving control + reaching a goal) with reinforcement learning; and, ($b$) the simulation environment developed is the first \textit{open-source}, physics-based platform that brings together tracked/wheeled vehicle dynamics, sensor, and terrain simulation. %While the authors acknowledge that it is commonly known that simulated sensor data, specifically rendered camera images, do not directly translate well to reality, other contributions have focused on methods for bridging this gap, and this is not the focus of this paper.

Our goal is to demonstrate that off-road mobility of AVs can rely on simulation for the development of control policies; and, to report on tests that assess these policies' effectiveness. We do not comment on the transferability of the derived control policies \cite{sim2realGapEssex1995}. Rather than addressing this important issue, for which we actually do not have an answer yet, this contribution focuses on the learning and the platform that enabled it, including probing the robustness of the policy in simulation. Thus, in \S\ref{sec:relatedWork} we provide an overview of similar ongoing efforts in the simulation-in-robotics area. Section \S\ref{sec:simEnv} provides an outline of the simulation environment developed by this group. Section \S\ref{sec:end2endLearning} presents the end-to-end learning approached for off-road AV mobility. Simulation results are described in \S\ref{sec:demoTechnology}. The last section contains concluding remarks and directions of future work.

