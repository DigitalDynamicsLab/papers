%%%%%%%%%%%%%%%% based on Springer template for conference proceedings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{svproc}


% to typeset URLs, URIs, and DOIs
\usepackage{url}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}

\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{tabularx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{array}
\usepackage{booktabs}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage[title]{appendix}
\usepackage{empheq}


\def\UrlFont{\rmfamily}

\newcommand{\vect}[1]{\bm{#1}}
\newcommand{\mat}[1]{#1}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5


\begin{document}
\mainmatter              % start of a contribution
%
\title{Solving Non-smooth Dynamic Problems using \\ the 
Alternating Direction Method of Multipliers}
%
\titlerunning{Non-smooth dynamic problem}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Alessandro Tasora \and Dario Mangoni \and Simone Benatti}
%
\authorrunning{Alessandro Tasora et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Alessandro Tasora, Dario Mangoni, and Simone Benatti}
%
\institute{University of Parma, Department of Engineering and Architecture \\ V.le delle Scienze 181/A, 40121 ITALY\\
\email{alessandro.tasora@unipr.it},\\ WWW home page:
\texttt{http://digitaldynamicslab.unipr.it}
}

\maketitle              % typeset the title of the contribution

\begin{abstract}
We propose to use the Alternating Direction Method of Multipliers (ADMM) for solving the variational inequality that arises in non-smooth contact problems in multibody simulations. The ADMM method is based on simple computational primitives and offers good convergence properties especially for scenarios where loose tolerance on the precision can be accepted, thus making it attractive also for real-time applications. The method scales well with the problem size and require a small number of tuning parameters. Differently from other methods known in literature, such as fixed point iterations, it can easily handle problems that mix finite elements and rigid bodies, and it is only marginally affected by odd mass ratios or ill-posed problems. Another attractive feature is that it can be easily warm-started.
\keywords{ADMM, non-smooth dynamics, contact}
\end{abstract}
%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}

Simulation of complex systems involving multiple contacts between mechanical parts can lead to problems of non-smooth dynamics. In such framework, contacts and frictional effects are represented by set-valued functions, thus leading to a more complex mathematical framework respect to conventional smooth Ordinary Differential Equations (ODE) or Differential-Algebraic Equations (DAE). In the latter, in fact, frictional contacts are often approximated as smooth regularizations, hence introducing spring-like penalty forces that allow the adoption of typical ODE or DAE time integrators, but at the same time incurring in low stability unless very small time steps are used.


Following the seminal works by Moreau 
\cite{mor88,Jean1992} 
most formulations for non-smooth dynamical problems are based on Measure Differential Inclusions (MDI): just like differential inclusions they allow set-valued force laws (such as the Coulomb-Amontons dry friction model) but also generalize to the case where velocity is assumed to be a possibly discontinuous function of bounded variation in order to allow impulsive events.

These problems can be solved by means of special time stepping methods that offer superior robustness and stability at the cost of solving a complementarity problem, or more in general a Variational Inequality (VI), per each time step
 \cite{acary2008numerical}. 
In this context, unknowns to be solved are velocity measures and reaction impulses at contact points and at joints: in cases of many parts with lot of frictional contacts, the large dimension of the VI could lead to a bottleneck in the time stepping process. This stimulated lot of research on efficient numerical methods in the last three decades.  

One of the former approaches, presented in 
\cite{StTr95}  % LCP solved via Lemke
, was based on solving a Linear Complementarity Problem (LCP) per each time step. LCPs are sub cases of VIs, for whom a direct method (Lemke algorithm) does exist. However, direct LCP solvers offer exact solution at the cost of very expensive pivoting sub iterations that scale badly with increasing number of unknowns, and for these reason they are not much used nowadays.

On the other hand, approximate but efficient methods based on fixed-point iterations became popular in the area of real-time simulators and robotics \cite{Bender2014}.
In most cases they are based on stationary methods like Gauss-Seidell or Jacobi iterations interleaved with projections on friction cones. They can be used to solve the LCP or the Cone Complementarity Problem (CCP), another special case of the VI in which the multibody contact problem can be formulated.
Attempts were made in order to parallelize them and to increase their convergence, such as over-relaxation, Krasnoselskii-Mann smoothing and warm starting, 
\cite{massSplittingRichard2012,TasoraAnitescuCMAME10} % P-GS iteration
but in general they perform poorly when there are odd mass ratios, and when articulated mechanisms such as robots are added to the scenarios - in those cases convergence often stalls, and if the iteration is prematurely truncated, reaction impulses are badly estimated and mechanisms fall apart or bend, and objects might interpenetrate. 

Another option is to solve the CCP as an optimization problem, using first-order optimization methods such as 
the Nesterov accelerated projected gradient descend  
\cite{hammadTOG2015}
or the Barzilai-Borwein spectral projected gradient
\cite{heynIJNME2013}. These methods are based on a simple projection operator,  matrix-by-vector multiplications and inner products. Their convergence is better than for fixed points iterations, however they share with them the following issue: that they often require the building of a Delassus operator, that is a Schur complement matrix that is easy to compute in efficient (factored and sparse) format if diagonal masses are used because these can be easily inverted, but hard to handle if finite elements are added to the problem, because they introduce stiffness and damping matrices whose inverse would be needed as well.

A further class of solvers is represented by non-smooth newton methods, such as the one presented in 
\cite{Macklin2019} % Non-smooth Newton Method
, that assume a generic Nonlinear Complemetarity Problem (NCP), again a sub case of a VI, and represent the NCP complementarity constraints using non-smooth functions like the Fisher-Burmeister function. A generalized non-smooth Newton method can be used to find the zero of the functions, at the cost of solving a linear system per each iteration.

Under mild assumptions, the VI can be stated as a convex CCP, that can be also cast as an optimization problem, namely a Quadratic Program (QP) with convex constraints \cite{anitescuTasora2008}. For such a class of optimization problems, one can use Interior Point Methods (IPMs), a class of solvers that share some similarities with the above mentioned non-smooth Newton methods - for example the solution of a saddle-point linear system is required at each iteration. IPMs offer the best theoretical convergence. However, their implementation is quite intricate, and despite the encouraging theoretical properties, in practice they do not scale well for large problems. Also, there are no reliable ways to warm-start them
\cite{Mangoni2018}
.

Recently there has been a revival of Alternating Direction Method of Multipliers (ADMM) and similar operator-splitting methods for solving constrained optimization problems
\cite{Goldstein2014}. %  [2014 Alternating Direction Optimization Methods]. 
Even if the theoretical convergence of such methods is worse than the one of IPMs, recent developments showed that in practical scenarios they offer superior speed, scalability and robustness 
\cite{Cannon2019}. % [COSMO  conic operator splitting method for large convex problems].
An attractive property of ADMM is that it requires the solution of a linear system per each iteration, but unlike IPMs, such linear system most often remains unchanged during the iterations, so a factorization can be reused multiple times with a great benefit in terms of speed.

A similar scheme, based on a sequential unconstrained minimization technique, has been proposed in \cite{Yunt2006} for non-smooth dynamics and robotics.

In 
\cite{Stellato2020} % [OSQP: an operator splitting solver for quadratic programs].
a specialized ADMM method for quadratic problems with conic constraints has been presented: on the top of this method we develop a solver that can exploit the nature of non-smooth dynamical problems. 

% TO ADD IN EXTENDED VERSION
%In our embodiment, unknowns are primal variables (velocity measures) and dual variables (impulses in contact points and joints), cone constraints stem from the Coulomb friction law, and the system matrix includes terms from the mass matrices and from the tangent stiffness/damping matrices (hence it is sparse, but not necessarily diagonal).
%This paper will present a model for the non-smooth dynamics, it will show how to cast it as a QP with convex conic constraint, it will present the ADMM method to solve it, it will discuss practical implementation details and then it will show some benchmarks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5


\section{The non-smooth multibody model}

Different time stepping schemes have been proposed for MDIs, here we refer to the one discussed \cite{TasoraAnitescuCMAME10} without lack of generality. After regularization and convexification and discretization, the MDIs leads to a major numerical bottleneck to be solved at each time step: a (mixed) CCP with unknowns $\vect{v}$ and $\vect{\gamma}_\epsilon$: 

\begin{subequations}
	\begin{empheq}[left=\empheqlbrace]{align}
    M \vect{v} - \vect{k} - D_\epsilon \vect{\gamma}_\epsilon &= 0 \\
    D_{\epsilon}^T \vect{v}  + \vect{b}_\epsilon &= \vect{u}_\epsilon\\
    -\Upsilon^{\circ} \ni \vect{u}_\epsilon  \quad \bot &\quad  \vect{\gamma}_\epsilon \in \Upsilon
	\end{empheq}
	\label{eq:ChronoMCCP}
\end{subequations}

where 
\begin{itemize}
		\item unknown $\vect{v}$ is the speed at the end of the time step, 
		\item unknown $\vect{\gamma}_\epsilon$ is the reaction in contacts and bilateral joints, a vector-signed measure with Lebesgue decomposition in atomic parts (impacts) and continuous parts (continuous reactions),
    \item $M$ is a positive definite, block diagonal matrix containing masses and inertia tensors of the bodies
    \item $D_\epsilon$ is a sparse matrix, the transpose jacobian of all constraints
    \item $\vect{k}$ is a vector containing terms proportional to applied forces, among other things 
    \item $\vect{b}$ is a vector containing constraint stabilization terms, among other things
    \item $\Upsilon$ is the Cartesian product of all cones of admissible constraint forces, $\Upsilon = \bigtimes_i \Upsilon_i$
    \item if a frictional contact is added, $\Upsilon_i \subset \mathbb{R}^3$ is a second order Lorentz cone with aperture proportional to friction coefficient
    \item if a bilateral constraint is added, $\Upsilon_i = \mathbb{R}$ and $\Upsilon^\circ_i = \{0\}$
    \item if a unilateral constraint is added, $\Upsilon_i = \mathbb{R}^+$ and $\Upsilon^\circ_i = \mathbb{R}^-$
    \item $\Upsilon^{\circ}$ is the polar cone, opposite of the dual cone, i.e. $\Upsilon^{*} = -\Upsilon^\circ$.
\end{itemize}

For more details on the model we refer to 
\cite{negrutSerbanTasoraJCND2017}. % Posing Multibody Dynamics with Friction and Contact as a Differential Complementarity Problem

Introducing the Schur complement 
\[
N=D_{\epsilon}^T M^{-1} D_{\epsilon}
\]
and the vector
\[
\vect{r}_\epsilon = D_{\epsilon}^T M^{-1} \vect{k} + \vect{b}_\epsilon
\]
such that
\[
\vect{u}_\epsilon = N \vect{\gamma}_\epsilon + \vect{r}_\epsilon \, , 
\]
one can also write the problem as the following CCP:
\begin{align}
    -\Upsilon^{\circ} \ni  N \vect{\gamma}_\epsilon + \vect{r}_\epsilon 
    \quad \bot \quad  
    \vect{\gamma}_\epsilon \in \Upsilon
	\label{eq:ChronoCCP}
\end{align}

This CCP corresponds exactly to a first order optimality condition of a convex quadratic program:
\begin{subequations}
	\begin{empheq}[box=\fbox]{align}
	\text{min} \quad & \frac{1}{2} \vect{\gamma}_\epsilon^T N \vect{\gamma}_\epsilon + \vect{r}^T_\epsilon \vect{\gamma}_\epsilon \\
	\text{s.t.} \quad & \vect{\gamma}_\epsilon \in \Upsilon
	\end{empheq}
	\label{eq:ChronoCCP_min}
\end{subequations}
%
and in fact, the CCP \eqref{eq:ChronoCCP} can be written in the more conventional language of the KKT optimality conditions on \textit{dual variables} $\vect{y}$ multipliers, for $\vect{y}=-\vect{u}_\epsilon$ and \textit{primal variables} $\vect{\gamma}_\epsilon$:
\begin{subequations}
	\begin{align}
    N \vect{\gamma}_\epsilon + \vect{r}_\epsilon + I \vect{y} &= \vect{0} \\
    \vect{\gamma}_\epsilon &= \vect{z} \\
    \Upsilon \ni \vect{z}  \quad \bot &\quad \vect{y} \in \Upsilon^\circ  
	\end{align}
	\label{eq:ChronoCCP_kkt}
\end{subequations}
After the convex program \eqref{eq:ChronoCCP_min} is solved by ADMM, one can compute $\vect{v} = M^{-1}( \vect{k} + \bar{D}_\epsilon \vect{\gamma}_\epsilon)$ with a quick postprocessing step. 

The ADMM method in \cite{Stellato2020} can be used to solve problems in the form
\begin{subequations}
	\begin{align}
    P \vect{x} + \vect{q} + A^T \vect{y} &= \vect{0} \\
    A \vect{x} - \vect{b} &= \vect{z} \\
    \mathcal{C} \ni \vect{z}  \quad \bot &\quad \vect{y} \in \mathcal{N}_{C}(\vect{z})
	\end{align}
	\label{eq:OQSP_kkt}
\end{subequations}
and one can see that \eqref{eq:ChronoCCP_kkt} is a special case of \eqref{eq:OQSP_kkt} where $A=I$, $P=N$, $\mathcal{C}=\Upsilon$, $\vect{q}=\vect{r}$, $\vect{x}=\vect{\gamma}_\epsilon$, $\vect{b}=\vect{0}$, where some optimizations can take place because of the structure of our problem.

% TO ADD IN EXTENDED VERSION
%The ADMM method requires a fast way to perform a projection $\Pi_{\Upsilon}$ onto the friction cones $\Upsilon$ and a fast way to solve a linear problem with the matrix $A$. 

We remark that the ADMM method just makes the assumption of $\Upsilon$ being convex, so the problem can be generalized to $\vect{\gamma}_\epsilon \in \mathcal{C}$ where $\mathcal{C}$ is a generic convex set and at the same time we assume an associated 
% TO ADD IN EXTENDED VERSION
%\footnote{Not all dissipative constitutive models are associated, for example in some computational plasticity models the plastic flow might deviate respect to the normal to the yeld surface, and the Coulmb contact model itself is not associated -in fact the contact velocity $\vect{u}$ can range into a wider cone than the polar of the friction cone, but our DVI model compensates fur such effect. We will assume associated models heretofore, and we do not deal with non-associated models to avoid additional complexity for the moment.} 
flow $\vect{u}_\epsilon \in - \mathcal{N}_{C}(\vect{\gamma}_\epsilon)$. For instance, $\mathcal{C}$ could be a capped friction cone to represent plasticization of contacts, or a cone translated downward to represent possible adhesion in contact up to a threshold, or the Von Mises yield region if $\vect{\gamma}_\epsilon$ represent stresses in finite elments undergoing plasticization. 

Also, in sake of highest generality, in presence of finite elements one might need to use tangent stiffness matrices $K$ and damping matrices $D$ to accommodate an implicit integration scheme for stiff elements, and this means that the Schur complement would be computed as $N=D_{\epsilon}^T H^{-1} D_{\epsilon}$. Here $H$, taking the place of the original $M$ matrix, is rather a linear combination of $M$, $K$, $D$ (depending on the integration scheme) and in general is not diagonal anymore. 

% TO ADD IN EXTENDED VERSION
%This means that one cannot easily compute the Schur complement $N$, even in factored form, and this has some consequences on the implementation of the ADMM, that in fact we will rewrite in an unrolled form.


\section{The ADMM solver}

For variables $(\vect{x},\vect{z}) \in \mathbb{R}^m \times \mathbb{R}^n$, the ADMM methods solve constrained optimization problems with separable structure
\begin{subequations}
	\begin{align}
    \text{min} \quad  & f(\vect{x}) + g(\vect{z}) \\
	  \text{s.t.} \quad &  A \vect{x} + B \vect{z} - \vect{b} = \vect{0}
	\end{align}
	\label{eq:admm}
\end{subequations}
by introducing an augmented Lagrangian
\begin{align}
\mathcal{L}_{\rho}(\vect{x},\vect{z},\vect{y})= f(\vect{x}) + g(\vect{z}) + \vect{y}^T (A \vect{x} + B \vect{z} - \vect{b}) + \frac{\rho}{2} \norm{A \vect{x} + B \vect{z} - \vect{b}}^2
\end{align}
and by iterating over two minimization problems as in the following loop:
\begin{align}
 \vect{x}^{k+1} &\in \text{argmin} \mathcal{L}_{\rho}(\vect{x},\vect{z}^k,\vect{y}^k) \\
 \vect{z}^{k+1} &\in \text{argmin} \mathcal{L}_{\rho}(\vect{x}^{k+1},\vect{z},\vect{y}^k) \\
 \vect{y}^{k+1} &= \vect{y}^{k} + \rho ( A \vect{x}^{k+1} + B \vect{z}^{k+1} - \vect{b} )
 \label{eq:admm_iters}
\end{align}
Although the convergence is fast in the first iterations, it tends to deteriorate later as in fixed-point iterations; however in practical scenarios where loose tolerances can be accepted, the method proves to be very efficient and robust.

In order to rewrite \eqref{eq:ChronoCCP_min} as a sum of two functions as in \eqref{eq:admm}, we introduce the auxiliary variables 
$(\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}})$, 
we state the $\vect{\gamma}_\epsilon \in \Upsilon$ constraint by adding a non-smooth penalty function given by the indicator function 
$\mathcal{I}_\Upsilon (\vect{\gamma}_\epsilon)$ 
where $\mathcal{I}_\Upsilon(\vect{\gamma}_\epsilon)=0$ for $\vect{\gamma}_\epsilon \in \Upsilon$ and $=\infty$ otherwise, another indicator function 
$\mathcal{I}_{\vect{\gamma}_\epsilon = \vect{z}}(\vect{\gamma}_\epsilon,\vect{z})$,
and finally we have
\begin{subequations}
	\begin{align}
    \text{min} \quad & \frac{1}{2} \tilde{\vect{\gamma}}_\epsilon^T N \tilde{\vect{\gamma}}_\epsilon + \vect{r}^T_\epsilon \tilde{\vect{\gamma}}_\epsilon  +  \mathcal{I}_{\tilde{\vect{\gamma}}_\epsilon = \tilde{\vect{z}}}(\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}}) +  \mathcal{I}_\Upsilon(\vect{\gamma}_\epsilon)  \\
	  \text{s.t.} \quad & (\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}})  =  (\vect{\gamma}_\epsilon,\vect{z})
	\end{align}
	\label{eq:admm_mod}
\end{subequations}

We can write the augmented Lagrangian introducing two step size parameters $\sigma$ and $\rho$ and two vector of multipliers $\vect{w}$ and $\vect{y}$, obtaining:
\begin{align}
\mathcal{L}_{\sigma,\rho} \left((\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}}),(\vect{\gamma}_\epsilon,\vect{z}),(\vect{y},\vect{w})\right) &= 
\frac{1}{2} \tilde{\vect{\gamma}}_\epsilon^T N \tilde{\vect{\gamma}}_\epsilon + \vect{r}^T_\epsilon \tilde{\vect{\gamma}}_\epsilon  
+  \mathcal{I}_{\tilde{\vect{\gamma}}_\epsilon = \tilde{\vect{z}}}(\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}}) 
+  \mathcal{I}_\Upsilon(\vect{\gamma}_\epsilon) \nonumber \\
+ \vect{w}^T (\tilde{\vect{\gamma}}_\epsilon - \vect{\gamma}_\epsilon) 
&+ \frac{\sigma}{2} \norm{\tilde{\vect{\gamma}}_\epsilon - \vect{\gamma}_\epsilon}^2
+ \vect{y}^T (\tilde{\vect{z}} - \vect{z}) 
+ \frac{\rho}{2} \norm{\tilde{\vect{z}} - \vect{z}}^2
\end{align}
that is also, using the property $\vect{y}^T\vect{r} + \frac{\rho}{2}\norm{\vect{r}}^2 = \frac{\rho}{2}\norm{\vect{r}+\frac{1}{\rho} \vect{y}}^2 - \frac{1}{2\rho} \norm{y}^2$, the following
\begin{align}
\mathcal{L}_{\sigma,\rho} \left((\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}}),(\vect{\gamma}_\epsilon,\vect{z}),(\vect{y},\vect{w})\right) &= 
\frac{1}{2} \tilde{\vect{\gamma}}_\epsilon^T N \tilde{\vect{\gamma}}_\epsilon + \vect{r}^T_\epsilon \tilde{\vect{\gamma}}_\epsilon  
+  \mathcal{I}_{\tilde{\vect{\gamma}}_\epsilon = \tilde{\vect{z}}}(\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}}) 
+  \mathcal{I}_\Upsilon(\vect{\gamma}_\epsilon) \nonumber \\
+ \frac{\sigma}{2} \norm{\tilde{\vect{\gamma}}_\epsilon - \vect{\gamma}_\epsilon + \frac{1}{\sigma} \vect{w}}^2 
&- \frac{1}{2\sigma} \norm{w}^2
+ \frac{\rho}{2} \norm{\tilde{\vect{z}} - \vect{z} + \frac{1}{\rho} \vect{y}}^2
- \frac{1}{2\rho} \norm{y}^2
\end{align}

The first step of ADMM requires to compute 
\[
(\tilde{\vect{\gamma}}_\epsilon^{k+1},\tilde{\vect{z}}^{k+1}) = \text{argmin} \mathcal{L}_{\sigma,\rho} \left((\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}}),(\vect{\gamma}_\epsilon^k,\vect{z}^k),(\vect{y}^k,\vect{w}^k)\right)
\] 
This can be simplified remembering that $\vect{w}^k$ will always be zero, that some terms are constant and can be left out, and that the $\mathcal{I}_{\tilde{\vect{\gamma}}_\epsilon = \tilde{\vect{z}}}(\tilde{\vect{\gamma}}_\epsilon,\tilde{\vect{z}})$ term can be elided to turn finally the unconstrained $\text{argmin}\mathcal{L}_{\sigma,\rho}$ into the equality constrained optimization problem:
\begin{subequations}
	\begin{align}
    \text{min} \quad  &  \frac{1}{2} \tilde{\vect{\gamma}}_\epsilon^T N \tilde{\vect{\gamma}}_\epsilon + \vect{r}^T_\epsilon \tilde{\vect{\gamma}}_\epsilon  
+ \frac{\sigma}{2} \norm{\tilde{\vect{\gamma}}_\epsilon - \vect{\gamma}_\epsilon^k}^2
+ \frac{\rho}{2} \norm{\tilde{\vect{z}} - \vect{z}^k + \frac{1}{\rho} \vect{y}^k}^2 \\
	  \text{s.t.} \quad &  \tilde{\vect{\gamma}} = \tilde{\vect{z}}
	\end{align}
	\label{eq:admm_1a}
\end{subequations}
%
For such problem, the KKT conditions lead to the following linear problem:
\begin{align}
    \left[ N + (\sigma+\rho) I \right] \tilde{\vect{\gamma}}_\epsilon = \sigma \vect{\gamma}_\epsilon^k + \rho \vect{z}^k - \vect{r} - \vect{y}^k
		\label{eq:admm_1b}
\end{align}
%
The linear system \eqref{eq:admm_1b} can be solved as it is, but in our case it would be better to exploit the fact that the Schur matrix $N$ is a product $D_\epsilon^T H^{-1} D_\epsilon$. We would like to avoid computing $H^{-1}$, even storing a precomputed inverse for all iterations would be unpractical because often dense (except when $H$ is a diagonal mass matrix $M$). So we propose to replace \eqref{eq:admm_1b} with the equivalent saddle point problem:
\begin{subequations}
	\begin{align}
    \begin{bmatrix}
		 H   & D_\epsilon \\
		 D^T & -(\sigma+\rho) I
		\end{bmatrix}
		\begin{Bmatrix}
		 \vect{v}    \\
		 -\tilde{\vect{\gamma}}_\epsilon^{k+1} 
		\end{Bmatrix}
		=
		\begin{Bmatrix}
		 \vect{k} \\
		 -\vect{b}_\epsilon + \sigma \vect{\gamma}_\epsilon^k + \rho \vect{z}^k -\vect{y}^k 
		\end{Bmatrix}
	\end{align}
	\label{eq:admm_1c}
\end{subequations}
that, even if it introduces an auxiliary variable $\vect{v}$, is very sparse and does not require computing any $H^{-1}$.

A remarkable side effect of this approach is that its auxiliary variable $\vect{v}$ is also the velocity term in the original MDI 
\eqref{eq:ChronoMCCP}, so one does not need to compute it as $\vect{v}=H^{-1}(\vect{k} + D_\epsilon \vect{\gamma}_\epsilon )$ after the iteration converged because it is a byproduct of the linear solver.

The second step of ADMM is a minimization problem too, but it can be rephrased in terms of a projection on the separable set $\Upsilon$ of the friction cones, note that this requires an inexpensive and parallelizable operation. 

Using these results, and adding a Krasnoselskii-Mann relaxation factor $\alpha \in(0,2]$, one obtains the final algorithm:
%
\begin{subequations}
	\begin{align}
    \begin{bmatrix}
		 H   & D_\epsilon \\
		 D^T & -(\sigma+\rho) I
		\end{bmatrix}
		\begin{Bmatrix}
		 \vect{v}    \\
		 -\tilde{\vect{\gamma}}_\epsilon^{k+1}
		\end{Bmatrix}
		&=
		\begin{Bmatrix}
		 \vect{k} \\
		 -\vect{b}_\epsilon + \sigma \vect{\gamma}_\epsilon^k +\rho \vect{z}^k - \vect{y}^k 
		\end{Bmatrix}
		\\
		\vect{\gamma}^{k+1}_\epsilon &=\tilde{\vect{\gamma}}_\epsilon^{k+1} + (1-\alpha) \vect{\gamma}_\epsilon^k \\
		\vect{z}^{k+1} &= \Pi_\Upsilon \left( \alpha \tilde{\vect{\gamma}}_\epsilon^{k+1} + (1-\alpha) \vect{z}^k  + \frac{1}{\rho} \vect{y}^k \right) \\
		\vect{y}^{k+1} &= \vect{y}^k + \rho \left( \alpha \tilde{\vect{\gamma}}_\epsilon^{k+1} + (1-\alpha) \vect{z}^k - \vect{z}^{k+1} \right) \\
		\vect{r}_{\text{prim}} &= \vect{\gamma}_\epsilon^{k+1}-\vect{z}^{k+1} \\
		\vect{r}_{\text{dual}} &= N \vect{\gamma}_\epsilon^{k+1}+\vect{r}+\vect{y}^{k+1} 
	\end{align}
	\label{eq:admm_final}
\end{subequations}

The iteration is terminated when $\vect{r}_{\text{prim}}$ and $\vect{r}_{\text{dual}}$ fall under prescribed tolerances. We remark that setting proper values for $\rho$ is of fundamental importance in order to obtain a good speed of convergence. In most cases one can use heuristics and adjust $\rho$ only one or two times during the iterations, hence allowing to reuse the factorization of the linear system. Also, $\sigma$ acts similarly to a regularization term, and can be left to low values anyway.


\begin{figure}[!tbp]
\centering
\includegraphics[width=0.50\textwidth]{t8_convergence.pdf}
\includegraphics[width=0.35\textwidth, trim=0cm -3cm 0 3cm]{t8_snapshot.png}
\caption{Convergence of the ADMMM method within one time step of the wrecking ball benchmark (600 bricks in four walls): residual in frictional constraint violation compared to fixed point Jacobi iterations and to first-order SPG methods.}
\label{fig:t8}
\end{figure}


\begin{figure}[!tbp]
  \centering
	\includegraphics[width=0.32\textwidth]{tire_5.png}
  \includegraphics[width=0.32\textwidth]{tire_10.png}
	%\includegraphics[width=0.32\textwidth]{tire_15.png}
	\includegraphics[width=0.32\textwidth]{tire_20.png}
	\hfill
  \caption{\textsc{Test 5}. Large deformation of a finite element mesh colliding with a plane. Thanks to the non-smooth formulation, large time steps can be used (only ten steps have been used from start to end) and no penalty parameters must be used in contact points. Contacts between lugs and ground show zero interpenetration regardless of the stiffness of the mesh.}
	\label{fig:tire}
\end{figure}


\section{Results and conclusion}

We performed benchmarks involving multi-body systems with contacts between multiple parts, showing that the performance of the ADMM method is capable of handling problems that would converge too slowly using conventional projected fixed point methods (see Fig.\ref{fig:t8}) or even first-order SPG spectral methods \cite{heynIJNME2013}.
An additional benefit of ADMM, when compared with those methods, is that it does not require the computation of a Schur complement, hence it can be applied seamlessly to problems featuring a block-sparse matrix in place of the diagonal $M$ in \eqref{eq:ChronoMCCP}, such as when introducing stiffness and damping matrices for finite elements (see \ref{fig:tire}).

Our ADMM method requires few computational primitives: basically a projection of dual variables on conic sets, a backward solve of a linear system, and a forward solve. The latter is a computational bottleneck, but it can be performed only once per run, as the matrix does not change often during the iterations. 
A good estimation of the ADMM step size proved to be fundamental in achieving good convergence: using some heuristics we obtained an efficient auto-tuning algorithm. 
We noted that ADMM can be successfully applied to problems that exhibit temporal coherence because, unlike IPMs, it supports warm-starting.


\bibliographystyle{spmpsci}
\bibliography{refsMBS,refsOPT}



\end{document}
